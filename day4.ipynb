{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Stuff Documents 체인을 사용하여 완전한 RAG 파이프라인을 구현하세요.\n",
    "- 체인을 수동으로 구현해야 합니다.\n",
    "- 체인에 ConversationBufferMemory를 부여합니다.\n",
    "- 이 문서를 사용하여 RAG를 수행하세요: https://gist.github.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223\n",
    "- 체인에 다음 질문을 합니다:\n",
    "Aaronson 은 유죄인가요?\n",
    "그가 테이블에 어떤 메시지를 썼나요?\n",
    "Julia 는 누구인가요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음과 같은 절차대로 구현하면 챌린지를 해결할 수 있습니다.\n",
    "- (1) 문서 로드하기 : TextLoader 등 을 사용해서 파일에서 텍스트를 읽어옵니다. (Document Loaders 관련 문서\n",
    "- (2) 문서 쪼개기 : CharacterTextSplitter 등 을 사용해서 문서를 작은 문서 조각들로 나눕니다. Character Split 관련 문서\n",
    "- (3) 임베딩 생성 및 캐시 : OpenAIEmbeddings, CacheBackedEmbeddings 등 을 사용해 문서 조각들을 임베딩하고 임베딩을 저장합니다. Caching 관련 문서\n",
    "- (4) 벡터 스토어 생성 : FAISS 등 을 사용해서 임베딩된 문서들을 저장하고 검색할 수 있는 데이터베이스를 만듭니다. FAISS 관련 문서\n",
    "- (5) 대화 메모리와 질문 처리 : ConversationBufferMemory를 사용해 대화 기록을 관리합니다.\n",
    "- (6) 체인 연결 : 앞에서 구현한 컴포넌트들을 적절하게 체인으로 연결합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# 1. 문서 로드\n",
    "loader = UnstructuredFileLoader(\"./document.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# 2. 문서 쪼개기\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# 3. 임베딩 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# 4. 벡터 스토어 생성\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "# 5. 메모리 설정\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "# 6. 체인 생성\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\",temperature=0),\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: Aaronson 은 유죄인가요?\n",
      "Answer: 저는 그 질문에 대한 답을 알 수 없습니다.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "Answer: 그가 쓴 메시지는 다음과 같습니다:\n",
      "FREEDOM IS SLAVERY\n",
      "TWO AND TWO MAKE FIVE\n",
      "GOD IS POWER\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: Julia 는 누구인가요?\n",
      "Answer: Julia는 Winston과 함께 Party에 반항하고 사랑을 나누는 여성 캐릭터입니다. 그녀는 Winston에게 중요한 인물로 나타납니다.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 질문 순차적으로 하기\n",
    "questions = [\n",
    "    \"Aaronson 은 유죄인가요?\",\n",
    "    \"그가 테이블에 어떤 메시지를 썼나요?\", \n",
    "    \"Julia 는 누구인가요?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
