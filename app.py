import streamlit as st
from RAG import process_file, setup_chain

# Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="RAG Pipeline",
    page_icon="ğŸ“„",
    layout="wide"
)

# ì œëª© ë° ì„¤ëª…
st.title("RAG Pipeline with Streamlit ğŸ“„")
st.markdown("""
ì´ ì•±ì€ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  AIë¥¼ í†µí•´ ì§ˆë¬¸ì— ë‹µë³€ì„ ìƒì„±í•˜ëŠ” RAG (Retrieval-Augmented Generation) íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.  
ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì§ˆë¬¸ì„ ì…ë ¥í•´ë³´ì„¸ìš”!
""")

# Sidebar ì„¤ì •
with st.sidebar:
    st.header("ì„¤ì •")
    # OpenAI API í‚¤ ì…ë ¥
    api_key = st.text_input("OpenAI API Key", type="password")
    st.write("---")
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (.txt, .pdf, .docx)", type=["txt", "pdf", "docx"])
    # GitHub ë§í¬
    github_link = "https://github.com/data-ai-insight/gpt-challenge.git"
    st.markdown(f"[ğŸ”— GitHub ë¦¬í¬ì§€í† ë¦¬]({github_link})")

# API í‚¤ ì…ë ¥ í™•ì¸
if not api_key:
    st.warning("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    st.stop()

# íŒŒì¼ ì—…ë¡œë“œ í™•ì¸ ë° ì²˜ë¦¬
if uploaded_file:
    st.info("íŒŒì¼ì„ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
    retriever = process_file(uploaded_file)
    chain = setup_chain(retriever, api_key)
    st.success("íŒŒì¼ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì§ˆë¬¸ì„ ì‹œì‘í•˜ì„¸ìš”.")

    # ì±„íŒ… ì„¸ì…˜ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state["messages"] = []

    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state["messages"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    user_input = st.chat_input("íŒŒì¼ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì§ˆë¬¸í•˜ì„¸ìš”...")
    if user_input:
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        st.chat_message("user").markdown(user_input)
        st.session_state["messages"].append({"role": "user", "content": user_input})

        # AI ë‹µë³€ ìƒì„±
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            response = chain.invoke({"question": user_input})
            answer = response["answer"]

        # AI ë‹µë³€ í‘œì‹œ
        st.chat_message("assistant").markdown(answer)
        st.session_state["messages"].append({"role": "assistant", "content": answer})
else:
    st.info("ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ë©´ AIì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
